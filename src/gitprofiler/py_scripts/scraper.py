import os
import sys
import re
import json
import argparse


INPUT_FILEPATH = "output.txt"


class MegaLinterScraper():
    """
    Functions in this file were converted ad-hoc into methods
    of new MegaLinterScraper class for conveniance of import.

    Use `run()` function to scrape the file.
    """

    def open_file(self, filename: str, path: str) -> list:
        """Opens up a file in the same directory.

        Args:
            filename (str): self-explanatory

        Returns:
            list of loaded contents (as str) of the file
        """
        filepath = os.path.join(path, filename)
        try:
            with open(filepath, "r", encoding='utf-8') as loaded_file:
                return loaded_file.readlines()
        except FileNotFoundError:
            print(f"Couldn't find {filename} (path: {filepath}) file.")
            sys.exit(1)

    def find_summary_table_indexes(self, filedata: list) -> tuple:
        pattern_table_start = re.compile(r"(SUMMARY)+(-+\+)+")
        pattern_table_end = re.compile(r"\+(-+\+){6,}")
        idx_start, idx_end = None, None
        mid_section_found = False

        for idx, line in enumerate(filedata):
            if pattern_table_start.search(line):
                idx_start = idx+3

            elif pattern_table_end.search(line):
                if mid_section_found:
                    idx_end = idx
                    break
                else:
                    mid_section_found = True

        return idx_start, idx_end

    def find_duplicates_table_indexes(self, filedata: list) -> tuple:
        pattern_table_start = re.compile(r"┌(─+┬){6,}─+┐")
        pattern_table_end = re.compile(r"└(─+┴){6,}─+┘")
        idx_start, idx_end = None, None

        for idx, line in enumerate(filedata):
            if pattern_table_start.search(line):
                idx_start = idx+3

            elif pattern_table_end.search(line):
                idx_end = idx
                break

        return idx_start, idx_end

    def find_errors_in_summary_table(self, line: str) -> dict:
        values = line.split("|")
        return {
            "language": values[1].strip()[2:].lower(),
            "linter":   values[2].strip(),
            "files":    int(values[3].strip()) if values[3].strip().isdigit() else values[3].strip(),
            "fixed":    int(values[4].strip()) if values[4].strip() else None,
            "errors":   int(values[5].strip())
        }

    def find_percentages_in_duplicates_table(self, line: str) -> dict:
        values = line.split("│")
        if len(values) <= 1:
            return {}

        pattern_percentage = re.compile(r"([\w*.\w]*%)")
        pattern_number = re.compile(r"([\w]+) ")

        return {
            "language": values[1].strip(),
            "files":    int(values[2].strip()),
            "lines":    int(values[3].strip()),
            "tokens":   int(values[4].strip()),
            "clones":   int(values[5].strip()),
            "duplicate_lines_num":      int(pattern_number.findall(values[6].strip())[0]),
            "duplicate_lines_percent":  float(pattern_percentage.findall(values[6].strip())[0][:-1]),
            "duplicate_tokens_num":     int(pattern_number.findall(values[7].strip())[0]),
            "duplicate_tokens_percent": float(pattern_percentage.findall(values[7].strip())[0][:-1])
        }

    def save_output_json(self, output: list, output_filename: str):
        with open(output_filename, 'w') as json_file:
            json.dump(output, json_file, indent=4)
        print(f"Succesfully parsed and saved as {json_file.name}.")

    def run(self, input_filename: str, input_path: str = sys.path[0], output_filename: str = 'output.json'):
        inputfile = self.open_file(input_filename, input_path)
        output = []

        idxs = self.find_summary_table_indexes(inputfile)
        if idxs[0]:
            for idx in range(*idxs):
                parsed: dict = self.find_errors_in_summary_table(inputfile[idx])
                output.append(parsed)

        idxs = self.find_duplicates_table_indexes(inputfile)
        if idxs[0]:
            for idx in range(*idxs):
                parsed: dict = self.find_percentages_in_duplicates_table(inputfile[idx])
                if parsed:
                    output.append(parsed)

        self.save_output_json(output, output_filename)


def arguments_parser():
    parser = argparse.ArgumentParser(description="Mega Linter Data Scraper")
    parser.add_argument("-f", "--file", default=INPUT_FILEPATH,
                        help="Filename of the output file generated by Mega Linter. \
                        (default: %(default)s)")
    parser.add_argument("-f", "--file", default=INPUT_FILEPATH,
                        help="Filename of the output file generated by Mega Linter. \
                        (default: %(default)s)")
    return parser.parse_args()


def main():
    mls = MegaLinterScraper()
    mls.run(arguments_parser().file)


if __name__ == "__main__":
    main()
