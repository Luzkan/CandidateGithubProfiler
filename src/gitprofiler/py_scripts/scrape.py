import os
import sys
import re
import json
import argparse


INPUT_FILEPATH = "output.txt"


def open_file(filename: str) -> list:
    """Opens up a file in the same directory.

    Args:
        filename (str): self-explanatory

    Returns:
        list of loaded contents (as str) of the file
    """
    filepath = os.path.join(sys.path[0], filename)
    try:
        with open(filepath, "r", encoding='utf-8') as loaded_file:
            return loaded_file.readlines()
    except FileNotFoundError:
        print(f"Couldn't find {filename} (path: {filepath}) file.")
        sys.exit(1)


def find_summary_table_indexes(filedata: list) -> tuple:
    pattern_table_start = re.compile(r"(SUMMARY)+(-+\+)+")
    pattern_table_end = re.compile(r"\+(-+\+){6,}")
    idx_start, idx_end = None, None
    mid_section_found = False

    for idx, line in enumerate(filedata):
        if pattern_table_start.search(line):
            idx_start = idx+3

        elif pattern_table_end.search(line):
            if mid_section_found:
                idx_end = idx
                break
            else:
                mid_section_found = True

    return idx_start, idx_end


def find_duplicates_table_indexes(filedata: list) -> tuple:
    pattern_table_start = re.compile(r"┌(─+┬){6,}─+┐")
    pattern_table_end = re.compile(r"└(─+┴){6,}─+┘")
    idx_start, idx_end = None, None

    for idx, line in enumerate(filedata):
        if pattern_table_start.search(line):
            idx_start = idx+3

        elif pattern_table_end.search(line):
            idx_end = idx
            break

    return idx_start, idx_end


def find_errors_in_summary_table(line: str) -> dict:
    values = line.split("|")
    return {
        "language": values[1].strip()[2:].lower(),
        "linter":   values[2].strip(),
        "files":    int(values[3].strip()) if values[3].strip().isdigit() else values[3].strip(),
        "fixed":    int(values[4].strip()) if values[4].strip() else None,
        "errors":   int(values[5].strip())
    }


def find_percentages_in_duplicates_table(line: str) -> dict:
    values = line.split("│")
    if len(values) <= 1:
        return {}

    pattern_percentage = re.compile(r"([\w*.\w]*%)")
    pattern_number = re.compile(r"([\w]+) ")

    return {
        "language": values[1].strip(),
        "files":    int(values[2].strip()),
        "lines":    int(values[3].strip()),
        "tokens":   int(values[4].strip()),
        "clones":   int(values[5].strip()),
        "duplicate_lines_num":      int(pattern_number.findall(values[6].strip())[0]),
        "duplicate_lines_percent":  float(pattern_percentage.findall(values[6].strip())[0][:-1]),
        "duplicate_tokens_num":     int(pattern_number.findall(values[7].strip())[0]),
        "duplicate_tokens_percent": float(pattern_percentage.findall(values[7].strip())[0][:-1])
    }


def arguments_parser():
    parser = argparse.ArgumentParser(description="Mega Linter Data Scraper")
    parser.add_argument("-f", "--file", default=INPUT_FILEPATH,
                        help="Filename of the output file generated by Mega Linter. \
                        (default: %(default)s)")
    return parser.parse_args()


def save_output_json(output: list):
    with open('output.json', 'w') as json_file:
        json.dump(output, json_file, indent=4)
    print(f"Succesfully parsed and saved as {json_file.name}.")


def main():
    arguments = arguments_parser()
    inputfile = open_file(arguments.file)
    output = []

    idxs = find_summary_table_indexes(inputfile)
    if idxs[0]:
        for idx in range(*idxs):
            parsed: dict = find_errors_in_summary_table(inputfile[idx])
            output.append(parsed)

    idxs = find_duplicates_table_indexes(inputfile)
    if idxs[0]:
        for idx in range(*idxs):
            parsed: dict = find_percentages_in_duplicates_table(inputfile[idx])
            if parsed:
                output.append(parsed)

    save_output_json(output)


if __name__ == "__main__":
    main()
