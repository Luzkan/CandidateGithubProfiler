
%% NEW %%

\subsection{Creating a Machine Learning Model}
We decided to chose \code{mlr} \footnote{mlr Website: https://mlr.mlr-org.com/} package as a tool which assists in creation of machine learning models and which is by far one of the most convenient machine learning packages in R. \footnote{R Website: https://www.r-project.org/}. We have performed the following processes:

As our first step, we began by importing the data from the \code{csv} file \footnote{The \code{csv} file is available at the ,,\code{./data/cleaned_data.csv}'' path in this project repository} with appropriate  \code{UTF-8} encoding into a data frame.
%% Dalej PL %% 
Then, in our first approach to the task, we have split the data into two separate data sets, one of which is the training set which consist of 75\% of our data and the other - testing set with the remaining rest. 

Now, after the data set is ready, we can proceed towards the creation of the machine learning model. First, we have defined a learning task for classification. We have specified \code{Task ID}, \code{Process Data} and \code{Target Column}.

%% OLD %%

Finally, the datasets were prepared and ready to use. The first step toward creating a machine learning model was to define a learning task for a classification. We specified task ID, data used in process and a target column, which had to be a factor, with a \emph{makeClassifTask()} method. Subsequently, we constructed a learner by calling \emph{makeLearner()} method. We needed to choose a classification algorithm. In the beginning, \emph{randomForest} was selected. Afterwards, we trained the model with a \emph{train()} method. We were supposed to specify train subset, use defined task and learner. In the end, we predicted the target values for test dataset. We had to specify using machine learning model and task with a \emph{predict()} method as well. Moreover, by calling \emph{makeResampleDesc()} method we determined a resampling strategy used in our process. We selected a cross-validation as our strategy in order to estimate precisely how accurately a predictive model will perform in practice. Initially, we set 10-fold cross-validation type which means we used cross-validation with 10 iterations.

%% PL %% 
Preprocessing?
Wszysktie dotychasz uzyskane dane (wyniki z ankiet, github api, megalinter) zostały zebrane do jednego pliku csv. Odfilrotwani zostali wszyscy użytkownicy, którzy nie podali odpowiedniego języka, linka do githuba lub ich repozytoria nie mogły zostać zlinotwane np. ze względu na brak publicznych repozytoriów. Na ich podstawie zdefiniowaliśmy cechy, które posłużą do utworzenia modelu ml. Wybrane przez nas cechy to : czasem bycia na rynku pracy (ExperienceDuration), czasem znalezienia pracy (WorkFindTime), średni czas pomiędzy comittami (avgCommitTim), typ doświadczenia (expType), umiejętności miękkię (softSkills), liczba linii zduplikowanych przez liczbę wszystkich linii (dupLines\_lines), liczba wszyskich linii przez liczbę plików (lines\_files). Współczynniki expTyp oraz softSkills są to średnie ważone, obliczane na podstawie danych z ankiety zawierających informacje o umiejątnościach miękkich i rodzaju doświadczenia użytkowników. Waga dla najważniejszej wartośi - communicativeness została ustawiona na 2. Waga dla reszy wartości została ustawiona na 1. Współczynnk duplines\_lines jest obliczany jako liczba zduplikowanych linii przez wszystie linie, natomiast współczynnik lines\_files jest obliczany jako liczba wszyskich linni przez liczbę wszystkich plików. Brakujące wartości dotyczące avgCommitTim zostały uzupełnione poprzez obliczenie średniej wartości.
 

Dane zostały zalabelowane na podstawie analizy aktualnych inforamcji o użytkownikach. Nastepnie przeszliśmy do analizy korelacji między danymi (Rys). Widać, że zmienne przygotowane do uczenia modelu nie są ze sobą skorelowane, największa korelacja występuje między czasem znalezienia pracy(WorkFindTime), a czasem bycia na rynku pracy (ExperienceDuration)

\begin{figure}[htp]
\centering
\includegraphics[width=11cm]{Rplot_corrrelation}
\caption{Correlation matrix}
\label{fig:correlation-matrix}
\end{figure}

Uczenie modelu rozpoczeliśmy od zdefiniowania odpowiedniego task'a, w którym określiliśmy dane na podstawie których będzie budowany model oraz kolumnę targett, która określa czy dany użytkowik jest wart uwagi ze strony rekruterów. Do weryfikacji poprawności modelu wykorzystaliśmy repeated k-fold cross validation. Parametry walidacji przezentują sie następująco 4 foldy i 10 repeatów. 

Zdecydowaliśmy się na porówanie wyników dla trzech różnych modeli. Wyniki badań zaprezentowane są w tabeli poniżej (to w resultsach chyba).
\begin{center}
\begin{tabular}{ | m{5em} | m{5em}| m{5em} | m{5em}| m{5em} | m{5em}| } 
\hline
 Alghoritm & MMCE & MCC & F1 & ACC & Kappa\\ 
 \hline
 Random Forest & 0.329 & 0.245 & 0.410 & 0.671 & 0.219 \\ 
\hline
 SVM & 0.315 & 0.356 & 0.422 & 0.685 & 0.311 \\ 
\hline
 KNN & 0.388 & 0.224 & 0.431 & 0.611 & 0.184\\ 
\hline
\end{tabular}
\end{center}