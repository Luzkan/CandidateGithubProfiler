\subsection{Data Preprocessing}

\subsubsection{Questionnaire}

In total, we received 67 completed questionnaires and 45 of them were provided with GitHub profile. The data file was further cleaned and reformatted with the use of Python \footnote{Python Website: https://www.python.org/} script. Both the original and formatted CSV files can be found in the project source under the name \emph{,,questionnaire.csv''} and \emph{,,cleaned\_data.csv''} as well as the Python script used for data formatting can be found in \emph{,,py\_scripts''} directory under the name ,,questionnaire\_adjuster.py''. To run the script, one must have Python 3.9 or newer installed on the machine along with "Numpy" \footnote{Numpy PyPI Page - https://pypi.org/project/numpy/}, "Pandas" \footnote{Pandas PyPI Page - https://pypi.org/project/pandas/} and "Requests" \footnote{Requests PyPI Page - https://pypi.org/project/requests/} packages.

\subsubsection{Repositories}

One of the most difficult tasks is to properly obtain information from the repositories of a given user. For research purposes, we decided to track them for potential errors and warnings which can be identified via linters. Linter is a static code analysis tool used to flag any bugs, errors, stylistic warnings, suspicious constructs, redundant code and more depending on the language and/or tool. Of course, the user could have repositories with code written in any language that exists, and that is a real problem, which we mitigated by a linter-aggregating tool - \emph{Mega Linter} \footnote{MegaLinter GitHub Page - https://github.com/nvuillam/mega-linter}. Mega Linter is an open-source tool that simply detects the languages used in a given project and then uses all available linters to scan it through. After the scan, it prints out a summary table with the number of Files that were detected and scanned with a given linter, the number of fixed files automatically during the run time, and the number of errors that couldn't be automatically fixed. There's also a second table that's printed somewhere in the first half of the output log that has information about detected duplicate lines and tokens in the project. To obtain that data we redirected the output stream into a file and then parsed it with Python script \emph{,,scrape.py''} which can be found in \emph{,,py\_scripts''} folder.

The usage of the Mega Linter and scrape script is more widely described in the main \emph{README.md} file although, in short, one must have Docker \footnote{Docker Website - https://www.docker.com/} and Python installed. Then, simply navigate to the repository which you would like to lint and run a command \ref{lst:shell-command-run-linter} which will generate an \emph{output.txt} file.

\begin{lstlisting}[language=Bash, label={lst:shell-command-run-linter}]
npx mega-linter-runner --flavor all
                  -e 'ENABLE=,DOCKERFILE,MARKDOWN,YAML'
                  -e 'SHOW_ELAPSED_TIME=true'
                 > output.txt
\end{lstlisting}

Copy the file and paste it in the \emph{scrape.py} directory. Finally use \ref{lst:shell-command-scrape-py} command which will generate an \emph{output.json} with a list of dictionaries structured as in \ref{lst:scrape-py-output-example}.

\begin{lstlisting}[language=Bash, label={lst:shell-command-scrape-py}]
python scrape.py -f output.txt
\end{lstlisting}

\begin{lstlisting}[language=Python, label={lst:scrape-py-output-example}]
{
 "language": str,
 "linter": str,
 "files": int or str, #detected files in given language
 "fixed": int,        #fixed errors automatically
 "errors": int        #errors that could not be fixed
},

or

{
 "language": str,
 "files": int,        #in a given language
 "lines": int,        #in a given language
 "tokens": int,       #("chars") in a given language
 "clones": int,
 "duplicate_lines_num": int,
 "duplicate_lines_percent": float,
 "duplicate_tokens_num": int,
 "duplicate_tokens_percent": float
},
\end{lstlisting}
